{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How_to_Avoid_Data_Leakage_When_Performing_Data_Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaKOEa5SDpFg0/cr+UfgXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishdb38/All_DL/blob/master/How_to_Avoid_Data_Leakage_When_Performing_Data_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfVWCIS7R-QZ"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBlXXGAbXgWA"
      },
      "source": [
        "## Data Preparation with Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFaytXysXjrf",
        "outputId": "717628ae-d800-40ce-ac00-4813a7ad6354"
      },
      "source": [
        "# Test Classification dataset\r\n",
        "from sklearn.datasets import  make_classification\r\n",
        "\r\n",
        "# define dataset\r\n",
        "x,y = make_classification(n_samples = 1000, n_features = 20, n_informative = 15, n_redundant = 5, random_state = 7)\r\n",
        "\r\n",
        "# Summarize the dataset\r\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 20) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "2oeuVjGSX43D",
        "outputId": "5bf7925f-91a6-44a3-cb0c-f3c8cb9c41b1"
      },
      "source": [
        "# Running the above creates an artificial datasets.\r\n",
        "# 1000 rows and 20 Column\r\n",
        "pd.DataFrame(x[:5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.292995</td>\n",
              "      <td>-4.212231</td>\n",
              "      <td>-1.288332</td>\n",
              "      <td>-2.178498</td>\n",
              "      <td>-0.645277</td>\n",
              "      <td>2.580977</td>\n",
              "      <td>0.284224</td>\n",
              "      <td>-7.182793</td>\n",
              "      <td>-1.912111</td>\n",
              "      <td>2.737295</td>\n",
              "      <td>0.813957</td>\n",
              "      <td>3.969737</td>\n",
              "      <td>-2.669398</td>\n",
              "      <td>3.346923</td>\n",
              "      <td>4.197918</td>\n",
              "      <td>0.999910</td>\n",
              "      <td>-0.302019</td>\n",
              "      <td>-4.431706</td>\n",
              "      <td>-2.826467</td>\n",
              "      <td>0.449168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.068399</td>\n",
              "      <td>5.518841</td>\n",
              "      <td>11.238977</td>\n",
              "      <td>-5.039700</td>\n",
              "      <td>-2.086784</td>\n",
              "      <td>2.149685</td>\n",
              "      <td>0.559734</td>\n",
              "      <td>15.113777</td>\n",
              "      <td>-3.071834</td>\n",
              "      <td>-2.574584</td>\n",
              "      <td>3.324576</td>\n",
              "      <td>2.067542</td>\n",
              "      <td>-5.249258</td>\n",
              "      <td>-2.154500</td>\n",
              "      <td>4.931091</td>\n",
              "      <td>1.296735</td>\n",
              "      <td>-3.186133</td>\n",
              "      <td>-3.089948</td>\n",
              "      <td>1.190299</td>\n",
              "      <td>1.620256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.731616</td>\n",
              "      <td>-0.684686</td>\n",
              "      <td>-0.981742</td>\n",
              "      <td>-2.552465</td>\n",
              "      <td>-5.270308</td>\n",
              "      <td>-1.561498</td>\n",
              "      <td>-1.169269</td>\n",
              "      <td>-2.104087</td>\n",
              "      <td>-1.131139</td>\n",
              "      <td>4.654775</td>\n",
              "      <td>-2.786596</td>\n",
              "      <td>-2.034761</td>\n",
              "      <td>2.149657</td>\n",
              "      <td>-0.134154</td>\n",
              "      <td>-1.198231</td>\n",
              "      <td>-2.720604</td>\n",
              "      <td>-0.123961</td>\n",
              "      <td>5.654297</td>\n",
              "      <td>-0.646599</td>\n",
              "      <td>-3.156530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.309107</td>\n",
              "      <td>-0.320548</td>\n",
              "      <td>-6.591664</td>\n",
              "      <td>1.070525</td>\n",
              "      <td>-4.418769</td>\n",
              "      <td>1.134274</td>\n",
              "      <td>2.340813</td>\n",
              "      <td>-5.983425</td>\n",
              "      <td>0.675917</td>\n",
              "      <td>-1.007879</td>\n",
              "      <td>-0.761441</td>\n",
              "      <td>6.866297</td>\n",
              "      <td>1.442270</td>\n",
              "      <td>1.768678</td>\n",
              "      <td>5.173661</td>\n",
              "      <td>-1.070164</td>\n",
              "      <td>-2.447064</td>\n",
              "      <td>-1.109038</td>\n",
              "      <td>-2.997035</td>\n",
              "      <td>1.993212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.488406</td>\n",
              "      <td>-3.213065</td>\n",
              "      <td>1.100805</td>\n",
              "      <td>-1.356223</td>\n",
              "      <td>5.325086</td>\n",
              "      <td>0.729179</td>\n",
              "      <td>-0.257040</td>\n",
              "      <td>-1.035284</td>\n",
              "      <td>0.478013</td>\n",
              "      <td>-0.010764</td>\n",
              "      <td>-0.227408</td>\n",
              "      <td>2.551456</td>\n",
              "      <td>0.951594</td>\n",
              "      <td>-2.914910</td>\n",
              "      <td>-2.186843</td>\n",
              "      <td>-1.089129</td>\n",
              "      <td>1.406454</td>\n",
              "      <td>3.082424</td>\n",
              "      <td>0.925835</td>\n",
              "      <td>-2.326362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1          2   ...        17        18        19\n",
              "0  0.292995 -4.212231  -1.288332  ... -4.431706 -2.826467  0.449168\n",
              "1 -0.068399  5.518841  11.238977  ... -3.089948  1.190299  1.620256\n",
              "2  0.731616 -0.684686  -0.981742  ...  5.654297 -0.646599 -3.156530\n",
              "3  2.309107 -0.320548  -6.591664  ... -1.109038 -2.997035  1.993212\n",
              "4 -0.488406 -3.213065   1.100805  ...  3.082424  0.925835 -2.326362\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oCevkdBYMJj"
      },
      "source": [
        "# Next, we can evaluate our model on the scaled dataset, starting with their naive or incorrect approach."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rRiVNb3Yqlt"
      },
      "source": [
        "### Train-Test Evaluation with Naive Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Y4b-82YvB5"
      },
      "source": [
        "# The Naive approach involves first applying the data preparation method, then splitting the data before finally evaluating the model\r\n",
        "# We can normalize the input variables using MinMaxScaler class, \r\n",
        "# Which is first defined with the default configuration  scaling the data to the range 0-1.\r\n",
        "# then the fit transform on the dataset and apply it to the dataset in a single step.\r\n",
        "\r\n",
        "\r\n",
        "# The Result is normalized version of the input variables, where each column in the array is separately normalized(e.g. has its own minimum and maximum calculated)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc8-qgdRZpsJ"
      },
      "source": [
        "# Standardize the data set\r\n",
        "from sklearn.preprocessing import  MinMaxScaler\r\n",
        "scaler = MinMaxScaler()\r\n",
        "x = scaler.fit_transform(x) # fit and transorm , single step"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MydMjLG8Z3RL"
      },
      "source": [
        "# Split the data to train and test sets\r\n",
        "from sklearn.model_selection import  train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfQPBnbMaTPk",
        "outputId": "f6d7e40d-d657-47e4-9aac-c09b1f0a6523"
      },
      "source": [
        "print(x_train.shape,x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(700, 20) (300, 20) (700,) (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVPqcxKxaaHc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvKwtx3XbWFZ"
      },
      "source": [
        "## Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFQFWwXCbXWK",
        "outputId": "2ed1c421-d5ea-42ff-f5f0-34f222d26252"
      },
      "source": [
        "from sklearn.linear_model import  LogisticRegression\r\n",
        "# fit the model\r\n",
        "model = LogisticRegression()\r\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npMg3rXdbgez",
        "outputId": "016a9885-980e-4dc6-c27b-85c999b9a6eb"
      },
      "source": [
        "\r\n",
        "from sklearn.metrics import   accuracy_score\r\n",
        "# Evaluate the Model\r\n",
        "yhat = model.predict(x_test)\r\n",
        "\r\n",
        "#Evaluate the accuracy\r\n",
        "accuracy = accuracy_score(y_test, yhat)\r\n",
        "print(\"Accuracy of the Model \", accuracy * 100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the Model  84.33333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgiajLmxcSy7"
      },
      "source": [
        "### All above process in single"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw6wYTTwcHLL",
        "outputId": "403c1479-c250-4d59-b0cb-4131c6f80d01"
      },
      "source": [
        "# naive approach to normalizing the data before splitting the data and evaluating the model\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "# define dataset\r\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\r\n",
        "# standardize the dataset\r\n",
        "scaler = MinMaxScaler()\r\n",
        "X = scaler.fit_transform(X)\r\n",
        "# split into train and test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\r\n",
        "# fit the model\r\n",
        "model = LogisticRegression()\r\n",
        "model.fit(X_train, y_train)\r\n",
        "# evaluate the model\r\n",
        "yhat = model.predict(X_test)\r\n",
        "# evaluate predictions\r\n",
        "accuracy = accuracy_score(y_test, yhat)\r\n",
        "print('Accuracy: %.3f' % (accuracy*100))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 84.848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tq_aZnVcVUj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmwdOwvjccFG"
      },
      "source": [
        "## Train-Test Evaluation With Correct Data Preparation\r\n",
        "Fit the preparation on the training set, then apply the transformation to the train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etayvsKsctjD"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.33, random_state=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pmjTChtdhU4"
      },
      "source": [
        "# Fit MinMaxScaler on Training set, then apply the transform() function on the train and test sets to create a normalized version of each datasets.\r\n",
        "# define the scaler\r\n",
        "scaler = MinMaxScaler()\r\n",
        "# Fit on the training dataset\r\n",
        "scaler.fit(x_train)\r\n",
        "\r\n",
        "# scale the training set\r\n",
        "x_train = scaler.transform(x_train)\r\n",
        "\r\n",
        "# scale the test dataset\r\n",
        "x_test = scaler.transform(x_test)\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwOF3JpDecPM"
      },
      "source": [
        "# This avoids data leakage as the calculation of the minimum and maximum value for each \r\n",
        "# input variable is calculated using only the training dataset (x_train) instead of the entire dataset(x)\r\n",
        "\r\n",
        "# The Model can then be evaluated as before"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeaFXKjRewNS"
      },
      "source": [
        "# Try all these process together\r\n",
        "from sklearn.datasets import  make_classification\r\n",
        "from sklearn.model_selection import  train_test_split\r\n",
        "from sklearn.preprocessing import  MinMaxScaler\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}