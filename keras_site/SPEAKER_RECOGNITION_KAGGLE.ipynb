{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/masoudmzb/gradient-tape-tutorial-audio-proccesing-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our variables are defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down load data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"audio_train/16000_pcm_speeches\"\n",
    "\n",
    "my_audios_folder = 'audio'\n",
    "my_noises_folder = 'noise'\n",
    "\n",
    "DATASET_AUDIOS_PATH = os.path.join(DATASET_ROOT, my_audios_folder)\n",
    "DATASET_NOISES_PATH = os.path.join(DATASET_ROOT, my_noises_folder)\n",
    "\n",
    "# percentage of samples to use for validation\n",
    "valid_split = 0.1\n",
    "\n",
    "# Seed to use when shuffling the dataset and the noise\n",
    "shuffle_seed = 43\n",
    "\n",
    "# The sampling rate to use.\n",
    "# This is the one used in all of the audio samples.\n",
    "# We will resample all of the noise to this sampling rate.\n",
    "# This will also be the output size of the audio wave samples\n",
    "# (since all samples are of 1 second long)\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# The factor to multiply the noise with according to:\n",
    "#   noisy_sample = sample + noise * prop * scale\n",
    "#      where prop = sample_amplitude / noise_amplitude\n",
    "SCALE = 0.5\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Structure of data folders :\n",
    "#    \n",
    "#    main_directory/\n",
    "#    ...speaker_a/\n",
    "#    ...speaker_b/\n",
    "#    ...speaker_c/\n",
    "#    ...speaker_d/\n",
    "#    ...speaker_e/\n",
    "#    ...other/\n",
    "#    ..._background_noise_/\n",
    "#    After sorting, we end up with the following structure:\n",
    "#    \n",
    "#    main_directory/\n",
    "#    ...audio/\n",
    "#    ......speaker_a/\n",
    "#    ......speaker_b/\n",
    "#    ......speaker_c/\n",
    "#    ......speaker_d/\n",
    "#    ......speaker_e/\n",
    "#    ...noise/\n",
    "#    ......other/\n",
    "#    ......_background_noise_/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If folder `audio`, does not exist, create it, otherwise do nothing\n",
    "if os.path.exists(DATASET_AUDIOS_PATH) is False:\n",
    "    os.makedirs(DATASET_AUDIOS_PATH)\n",
    "\n",
    "# If folder `noise`, does not exist, create it, otherwise do nothing\n",
    "# MY OWN NOTE : LET's SEE tf.io.gfile\n",
    "if tf.io.gfile.exists(DATASET_NOISES_PATH) is False:\n",
    "    tf.io.gfile.makedirs(DATASET_NOISES_PATH)\n",
    "\n",
    "for folder in os.listdir(DATASET_ROOT):\n",
    "    if os.path.isdir(os.path.join(DATASET_ROOT, folder)):\n",
    "        if folder in [my_audios_folder, my_noises_folder]:\n",
    "            # If folder is `audio` or `noise`, do nothing\n",
    "            continue\n",
    "        elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            # If folder is one of the folders that contains noise samples,\n",
    "            # move it to the `noise` folder\n",
    "            shutil.move(\n",
    "                os.path.join(DATASET_ROOT, folder),\n",
    "                os.path.join(DATASET_NOISES_PATH, folder),\n",
    "            )\n",
    "        else:\n",
    "            # Otherwise, it should be a speaker folder, then move it to\n",
    "            # `audio` folder\n",
    "            shutil.move(\n",
    "                os.path.join(DATASET_ROOT, folder),\n",
    "                os.path.join(DATASET_AUDIOS_PATH, folder),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files belonging to 2 directories\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all noise files\n",
    "noise_paths = []\n",
    "for subdir in tf.io.gfile.listdir(DATASET_NOISES_PATH):\n",
    "    subdir_path = Path(DATASET_NOISES_PATH) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]\n",
    "\n",
    "print(\n",
    "    \"Found {} files belonging to {} directories\".format(\n",
    "        len(noise_paths), len(os.listdir(DATASET_NOISES_PATH))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = (\n",
    "    \"for dir in `ls -1 \" + DATASET_NOISES_PATH + \"`; do \"\n",
    "    \"for file in `ls -1 \" + DATASET_NOISES_PATH + \"/$dir/*.wav`; do \"\n",
    "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
    "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
    "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
    "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
    "    \"-i $file -ar 16000 temp.wav; \"\n",
    "    \"mv temp.wav $file; \"\n",
    "    \"fi; done; done\"\n",
    ")\n",
    "\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate for audio_train\\16000_pcm_speeches\\noise\\other\\exercise_bike.wav is incorrect. Ignoring it\n",
      "Sampling rate for audio_train\\16000_pcm_speeches\\noise\\other\\pink_noise.wav is incorrect. Ignoring it\n",
      "Sampling rate for audio_train\\16000_pcm_speeches\\noise\\_background_noise_\\10convert.com_Audience-Claps_daSG5fwdA7o.wav is incorrect. Ignoring it\n",
      "Sampling rate for audio_train\\16000_pcm_speeches\\noise\\_background_noise_\\doing_the_dishes.wav is incorrect. Ignoring it\n",
      "Sampling rate for audio_train\\16000_pcm_speeches\\noise\\_background_noise_\\dude_miaowing.wav is incorrect. Ignoring it\n",
      "Sampling rate for audio_train\\16000_pcm_speeches\\noise\\_background_noise_\\running_tap.wav is incorrect. Ignoring it\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d28abd85b0c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m print(\n\u001b[0;32m     24\u001b[0m     \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mSAMPLING_RATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Split noise into chunks of 16000 each\n",
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    if sampling_rate == SAMPLING_RATE:\n",
    "        # Number of slices of 16000 each that can be generated from the noise sample\n",
    "        slices = int(sample.shape[0] / SAMPLING_RATE)\n",
    "        sample = tf.split(sample[: slices * SAMPLING_RATE], slices)\n",
    "        return sample\n",
    "    else:\n",
    "        print(\"Sampling rate for {} is incorrect. Ignoring it\".format(path))\n",
    "        return None\n",
    "\n",
    "\n",
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)\n",
    "\n",
    "print(\n",
    "    \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n",
    "        len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
